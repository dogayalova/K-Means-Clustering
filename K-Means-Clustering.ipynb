{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e2882e6-124a-4952-b407-2636ad754059",
   "metadata": {},
   "source": [
    "-- QUESTION 1 --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246fc5b1-a927-4f0f-a29f-696a9b9f87f9",
   "metadata": {},
   "source": [
    "a) First 3 columns of the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b589010-35f3-4d31-9335-6e2fda079cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix = np.loadtxt(\"gene_expression_matrix.txt\", delimiter = \" \")\n",
    "\n",
    "print(f\"First three columns:\\n {matrix[:, :3]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1d9919-ec5a-40a9-af06-c96270d9b3e2",
   "metadata": {},
   "source": [
    "b) First 3 columns of the standardized matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f44133-2eee-4448-b3b3-9c6d446b05b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix = np.loadtxt(\"gene_expression_matrix.txt\", delimiter = \" \")\n",
    "\n",
    "mean_values = np.mean(matrix, axis=0)\n",
    "stdeviation_values = np.std(matrix, axis=0)\n",
    "\n",
    "standardized_matrix = (matrix - mean_values) / stdeviation_values\n",
    "\n",
    "print(f\"First three columns of standardize matrix:\\n {standardized_matrix[:, :3]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17514648-c57b-4b20-b09d-adec59e39f6e",
   "metadata": {},
   "source": [
    "c) Implementation of K-means Clustering Algorithm. Lloyd Algorithm is used which involves arbitrary assignment of k cluster centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e1fc6b-0166-412b-aeaa-ce555b6dc8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cosine_similarity_matrix(data, centroids):\n",
    "    # Normalisation of the data and centroids is essential for cosine similarity calculation in the next step. \n",
    "    #So that we already divide both vectors to their lengths in this step.\n",
    "    norm_data = data / np.linalg.norm(data, axis=1, keepdims=True)\n",
    "    norm_centroids = centroids / np.linalg.norm(centroids, axis=1, keepdims=True)\n",
    "\n",
    "    # Then we can compute cosine similarity matrix, with dot product.\n",
    "    similarity_matrix = np.dot(norm_data, norm_centroids.T)\n",
    "    return similarity_matrix\n",
    "\n",
    "def k_means(data, k, max_iterations=100):\n",
    "    # This function takes the data (62x2000 matrix), how many clusters we want (k) and max iterations (cluster updates).\n",
    "    # Initializes centroids randomly as in the algorithm.\n",
    "    centroids = data[np.random.choice(data.shape[0], k, replace=False)]\n",
    "\n",
    "    prev_centroids = None\n",
    "    iteration = 0\n",
    "\n",
    "    while not np.array_equal(centroids, prev_centroids) and iteration < max_iterations:\n",
    "        prev_centroids = centroids.copy()\n",
    "\n",
    "        # Cosine similarity matrix is computed.\n",
    "        similarity_matrix = cosine_similarity_matrix(data, centroids)\n",
    "\n",
    "        # Each data point is assigned to the nearest centroid.\n",
    "        labels = np.argmin(similarity_matrix, axis=1)\n",
    "\n",
    "        # Centroids are updated.\n",
    "        centroids = np.array([data[labels == i].mean(axis=0) for i in range(k)])\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    \n",
    "    # Squared error distortion is calculated by taking the squares of differences between each data point and its assigned centroid,\n",
    "    # and then summing the squared differences along each row (axis=1). Finally, the average of these sums across all data points are\n",
    "    #computed.This average gives the distortion.\n",
    "    distortion = np.mean(np.sum((data - centroids[labels]) ** 2, axis=1))\n",
    "\n",
    "    return labels, centroids, distortion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cff79eb-3afc-43e7-84a7-3f1852d7f2ca",
   "metadata": {},
   "source": [
    "d) K-Means Algorithm is run 5 times on the given data. Square error distortion for each solution is reported.\n",
    "\n",
    "e) For the clustering solution with the lowest squared error distortion, percentage of cancer patients without including the 62nd patient is resported. Cluster of 62nd patient is also reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9716c3fb-ca68-4185-b052-faa045ee7456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a 62x2000 matrix.\n",
    "# Standardized matrix should be used when using cosine similarity.\n",
    "\n",
    "results_dict = {}\n",
    "min_distortion = float('inf')\n",
    "best_iteration = None\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    labels, centroids, distortion = k_means(standardized_matrix, 2)\n",
    "\n",
    "    # Results are printed.\n",
    "    print(f\"\\nClustering Solution {i+1}:\")\n",
    "    print(\"Cluster labels for each person:\", labels)\n",
    "    print(\"Centroids:\", centroids)\n",
    "    print(\"Squared Error Distortion:\", distortion)\n",
    "\n",
    "    # Results are stored in a dicitonary.\n",
    "    results_dict[f'Iteration {i+1}'] = {'labels': labels.tolist(),'distortion': distortion}\n",
    "\n",
    "    # Update of minimum distortion and corresponding iteration.\n",
    "    if distortion < min_distortion:\n",
    "        min_distortion = distortion\n",
    "        best_iteration = f'Iteration {i+1}'\n",
    "\n",
    "best_result = results_dict[best_iteration]\n",
    "print(f\"\\nResults for the iteration with the lowest squared error distortion ({best_iteration}):\")\n",
    "print(\"Cluster labels for each person:\", best_result['labels'])\n",
    "print(\"Squared Error Distortion:\", best_result['distortion'])\n",
    "\n",
    "\n",
    "cluster_0_cancer_patients = []\n",
    "cluster_1_cancer_patients = []\n",
    "\n",
    "#First 40 people are cancer patients.\n",
    "for idx, x in enumerate(best_result['labels']):\n",
    "    if idx <= 39 and x == 0:\n",
    "        cluster_0_cancer_patients.append(x)\n",
    "    elif idx <= 39 and x == 1:\n",
    "        cluster_1_cancer_patients.append(x)\n",
    "        \n",
    "cluster_0_all = best_result['labels'][:-1].count(0)\n",
    "cluster_1_all = best_result['labels'][:-1].count(1)\n",
    "    \n",
    "\n",
    "cluster_0_percentage = len(cluster_0_cancer_patients)/40 * 100\n",
    "cluster_1_percentage = len(cluster_1_cancer_patients)/40 * 100\n",
    "\n",
    "print(f\"\\nPercentage for cancer patients in Cluster 0 is: {cluster_0_percentage}\")\n",
    "print(f\"Percentage for cancer patients in Cluster 1 is: {cluster_1_percentage}\")\n",
    "print(f\"The 62nd patient was assigned in the Cluster {best_result['labels'][-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b6b5e-117b-4745-8be2-e7ac2f9ad83f",
   "metadata": {},
   "source": [
    "f) Based on the results in (e), the percentages of cancer patients compared to overall cancer patients for two clusters are nearly around 40% and 60%. If we can say that cluster with 40% cancer patients indicates \"healthy cluster\" and 60% indicates \"cancer patients\", we can conclude that 62nd patient might be healthy, since she/he is always assigned to the cluster with the lower cancer patient percentage. I would say it is not quite reliable (not significant) due to the \"locally optimum\" drawback of k-means clustering (Lloyd Algorithm). Converging in k-means doesn't mean we converge to the optimal clustering. In this manner, the seeds we start come into question. Seeds can be chosen other than randomizing method such as using some heuristic or using hierarchical clustering to find good seeds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
